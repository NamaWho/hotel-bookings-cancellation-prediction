{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset available [here](https://www.sciencedirect.com/science/article/pii/S2352340918315191?via%3Dihub)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "Pp6o37MGITM1",
        "outputId": "859d0c44-0c78-496f-d6fe-b96068c72337"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IsCanceled</th>\n",
              "      <th>LeadTime</th>\n",
              "      <th>ArrivalDateYear</th>\n",
              "      <th>ArrivalDateMonth</th>\n",
              "      <th>ArrivalDateWeekNumber</th>\n",
              "      <th>ArrivalDateDayOfMonth</th>\n",
              "      <th>StaysInWeekendNights</th>\n",
              "      <th>StaysInWeekNights</th>\n",
              "      <th>Adults</th>\n",
              "      <th>Children</th>\n",
              "      <th>...</th>\n",
              "      <th>Agent</th>\n",
              "      <th>Company</th>\n",
              "      <th>DaysInWaitingList</th>\n",
              "      <th>CustomerType</th>\n",
              "      <th>ADR</th>\n",
              "      <th>RequiredCarParkingSpaces</th>\n",
              "      <th>TotalOfSpecialRequests</th>\n",
              "      <th>ReservationStatus</th>\n",
              "      <th>ReservationStatusDate</th>\n",
              "      <th>Hotel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>342</td>\n",
              "      <td>2015</td>\n",
              "      <td>July</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>0</td>\n",
              "      <td>Transient</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Check-Out</td>\n",
              "      <td>2015-07-01</td>\n",
              "      <td>Resort Hotel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>737</td>\n",
              "      <td>2015</td>\n",
              "      <td>July</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>0</td>\n",
              "      <td>Transient</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Check-Out</td>\n",
              "      <td>2015-07-01</td>\n",
              "      <td>Resort Hotel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>July</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>0</td>\n",
              "      <td>Transient</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Check-Out</td>\n",
              "      <td>2015-07-02</td>\n",
              "      <td>Resort Hotel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>2015</td>\n",
              "      <td>July</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>304</td>\n",
              "      <td>NULL</td>\n",
              "      <td>0</td>\n",
              "      <td>Transient</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Check-Out</td>\n",
              "      <td>2015-07-02</td>\n",
              "      <td>Resort Hotel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>2015</td>\n",
              "      <td>July</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>240</td>\n",
              "      <td>NULL</td>\n",
              "      <td>0</td>\n",
              "      <td>Transient</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Check-Out</td>\n",
              "      <td>2015-07-03</td>\n",
              "      <td>Resort Hotel</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   IsCanceled  LeadTime  ArrivalDateYear ArrivalDateMonth  \\\n",
              "0           0       342             2015             July   \n",
              "1           0       737             2015             July   \n",
              "2           0         7             2015             July   \n",
              "3           0        13             2015             July   \n",
              "4           0        14             2015             July   \n",
              "\n",
              "   ArrivalDateWeekNumber  ArrivalDateDayOfMonth  StaysInWeekendNights  \\\n",
              "0                     27                      1                     0   \n",
              "1                     27                      1                     0   \n",
              "2                     27                      1                     0   \n",
              "3                     27                      1                     0   \n",
              "4                     27                      1                     0   \n",
              "\n",
              "   StaysInWeekNights  Adults  Children  ...        Agent      Company  \\\n",
              "0                  0       2       0.0  ...         NULL         NULL   \n",
              "1                  0       2       0.0  ...         NULL         NULL   \n",
              "2                  1       1       0.0  ...         NULL         NULL   \n",
              "3                  1       1       0.0  ...          304         NULL   \n",
              "4                  2       2       0.0  ...          240         NULL   \n",
              "\n",
              "  DaysInWaitingList CustomerType   ADR  RequiredCarParkingSpaces  \\\n",
              "0                 0    Transient   0.0                         0   \n",
              "1                 0    Transient   0.0                         0   \n",
              "2                 0    Transient  75.0                         0   \n",
              "3                 0    Transient  75.0                         0   \n",
              "4                 0    Transient  98.0                         0   \n",
              "\n",
              "   TotalOfSpecialRequests  ReservationStatus ReservationStatusDate  \\\n",
              "0                       0          Check-Out            2015-07-01   \n",
              "1                       0          Check-Out            2015-07-01   \n",
              "2                       0          Check-Out            2015-07-02   \n",
              "3                       0          Check-Out            2015-07-02   \n",
              "4                       1          Check-Out            2015-07-03   \n",
              "\n",
              "          Hotel  \n",
              "0  Resort Hotel  \n",
              "1  Resort Hotel  \n",
              "2  Resort Hotel  \n",
              "3  Resort Hotel  \n",
              "4  Resort Hotel  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score, StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# load data\n",
        "data_h1 = pd.read_csv('./dataset/H1.csv')\n",
        "data_h2 = pd.read_csv('./dataset/H2.csv')\n",
        "data_h1['Hotel'] = 'Resort Hotel'\n",
        "data_h2['Hotel'] = 'City Hotel'\n",
        "data = pd.concat([data_h1, data_h2], ignore_index=True)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove duplicates\n",
        "data_cleaned = data.drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instead of making a stratified split by the outcome (IsCanceled) based on the dimension of the booking creation date, an approach usually employed in time series is applied, convenience splitting. Order the dataset by arrival date of bookings and create blocks of \"month/year\". Merge a 75% stratified split of each block into a training dataset and the remaining 25% into a test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "\n",
        "def split_data(data):\n",
        "    \"\"\"\n",
        "    Perform stratified split on the data\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "        The data to split\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X_train : pd.DataFrame\n",
        "        The training data\n",
        "    X_test : pd.DataFrame   \n",
        "        The testing data\n",
        "    y_train : pd.Series\n",
        "        The training target\n",
        "    y_test : pd.Series\n",
        "        The testing target\n",
        "    \"\"\"\n",
        "    \n",
        "    data = data.sort_values(by=['ArrivalDateYear', 'ArrivalDateMonth', 'ArrivalDateDayOfMonth'])\n",
        "    \n",
        "    X = data.drop(columns=['IsCanceled'])\n",
        "    y = data['IsCanceled']\n",
        "    \n",
        "    X['YearMonth'] = X['ArrivalDateYear'].astype(str) + '-' + X['ArrivalDateMonth'].astype(str)\n",
        "    \n",
        "    X_train_list, X_test_list, y_train_list, y_test_list = [], [], [], []\n",
        "    \n",
        "    # Loop over each block and perform stratified split\n",
        "    for block in X['YearMonth'].unique():\n",
        "        X_block = X[X['YearMonth'] == block].drop(columns=['YearMonth'])\n",
        "        y_block = y[X['YearMonth'] == block]\n",
        "        \n",
        "        X_train_block, X_test_block, y_train_block, y_test_block = train_test_split(\n",
        "            X_block, y_block, test_size=0.25, stratify=y_block, random_state=42)\n",
        "        \n",
        "        X_train_list.append(X_train_block)\n",
        "        X_test_list.append(X_test_block)\n",
        "        y_train_list.append(y_train_block)\n",
        "        y_test_list.append(y_test_block)\n",
        "    \n",
        "    X_train = pd.concat(X_train_list)\n",
        "    X_test = pd.concat(X_test_list)\n",
        "    y_train = pd.concat(y_train_list)\n",
        "    y_test = pd.concat(y_test_list)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def split_data_time_series(data, target_column, n_splits=5):\n",
        "    \"\"\"\n",
        "    Perform time series split on the data\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "        The data to split\n",
        "    target_column : str\n",
        "        The target column\n",
        "    n_splits : int\n",
        "        The number of splits to perform\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X_train : pd.DataFrame\n",
        "        The training data\n",
        "    X_test : pd.DataFrame\n",
        "        The testing data\n",
        "    y_train : pd.Series\n",
        "        The training target\n",
        "    y_test : pd.Series  \n",
        "        The testing target\n",
        "    \"\"\"\n",
        "    data = data.sort_values(by=['ArrivalDateYear', 'ArrivalDateMonth', 'ArrivalDateDayOfMonth'])\n",
        "    \n",
        "    X = data.drop(target_column, axis=1)\n",
        "    y = data[target_column]\n",
        "    \n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "    \n",
        "    for train_index, test_index in tscv.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        \n",
        "        # Ensure stratification by checking the distribution of the target variable\n",
        "        if np.all(np.bincount(y_train) > 0) and np.all(np.bincount(y_test) > 0):\n",
        "            break\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Selection and Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import datetime\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Custom transformer for feature engineering\n",
        "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, categorical_features, cardinality_threshold=0.02):\n",
        "        self.categorical_features = categorical_features\n",
        "        self.cardinality_threshold = cardinality_threshold\n",
        "        self.encoders = {}\n",
        "        self.imputers = {}\n",
        "        pass\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        self.fit_categorical_encodings(X, y)\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "\n",
        "        # Replace LeadTime with LiveTime\n",
        "        X['LiveTime'] = X.apply(self.calculate_livetime, axis=1)\n",
        "        \n",
        "        # Replace ADR with ADRThirdQuartileDeviation\n",
        "        X = self.calculate_adr_third_quartile_deviation(X)\n",
        "        \n",
        "        # Apply categorical encodings\n",
        "        X = self.apply_categorical_encodings(X)\n",
        "        \n",
        "        # Drop the original columns\n",
        "        columns_to_drop = ['LeadTime', 'ADR', 'ArrivalDateMonth', 'ArrivalDateDayOfMonth', \n",
        "                           'ArrivalDateWeekNumber', 'ArrivalDateYear', 'Country', \"AssignedRoomType\",\n",
        "                           'RequiredCarParkingSpaces', 'ReservedRoomType']\n",
        "        columns_to_drop.extend(self.categorical_features)\n",
        "        X.drop(columns=columns_to_drop, inplace=True)\n",
        "        \n",
        "        return X\n",
        "    \n",
        "    def calculate_livetime(self, row):\n",
        "        arrival_date = datetime.date(row['ArrivalDateYear'], row['ArrivalDateMonth'], row['ArrivalDateDayOfMonth'])\n",
        "        booking_date = arrival_date - datetime.timedelta(days=row['LeadTime'])\n",
        "        reservation_status_date = datetime.datetime.strptime(row['ReservationStatusDate'], '%Y-%m-%d').date()\n",
        "\n",
        "        if row['ReservationStatus'] == 'Check-Out' or row['ReservationStatus'] == 'No-Show':\n",
        "            return row['LeadTime']\n",
        "        else:\n",
        "            # If the reservation is canceled, the live time is the difference between the booking date and the cancel date\n",
        "            return (reservation_status_date - booking_date).days\n",
        "    \n",
        "    def calculate_adr_third_quartile_deviation(self, X):\n",
        "        # Group by the required factors\n",
        "        grouped = X.groupby(['DistributionChannel', 'ReservedRoomType', 'ArrivalDateWeekNumber', 'ArrivalDateYear'])\n",
        "\n",
        "        # Calculate the third quartile for each group\n",
        "        adr_third_quartile = grouped['ADR'].transform(lambda x: x.quantile(0.75))\n",
        "\n",
        "        # Calculate the deviation\n",
        "        X['ADRThirdQuartileDeviation'] = X['ADR'] / adr_third_quartile\n",
        "\n",
        "        # Handle cases where third quartile is 0 (unlikely, but possible)\n",
        "        X['ADRThirdQuartileDeviation'] = X['ADRThirdQuartileDeviation'].fillna(0)\n",
        "\n",
        "        return X\n",
        "    \n",
        "    def fit_categorical_encodings(self, X, y):\n",
        "        for feature in self.categorical_features:\n",
        "            # Calculate value counts and keep only those above the threshold\n",
        "            value_counts = X[feature].value_counts(normalize=True)\n",
        "            frequent_categories = value_counts[value_counts >= self.cardinality_threshold].index.tolist()\n",
        "            \n",
        "            # Fit OneHotEncoder for frequent categories\n",
        "            onehot = OneHotEncoder(handle_unknown='ignore')\n",
        "            onehot.fit(X[feature].values.reshape(-1, 1))\n",
        "            self.encoders[feature] = onehot\n",
        "            \n",
        "            # Calculate logit-odds\n",
        "            feature_grouped = pd.DataFrame({\n",
        "                'total': X.groupby(feature).size(),\n",
        "                'positive': X.groupby(feature)[y.name].sum()\n",
        "            })\n",
        "            feature_grouped['negative'] = feature_grouped['total'] - feature_grouped['positive']\n",
        "            feature_grouped['logit_odds'] = np.log((feature_grouped['positive'] + 0.5) / (feature_grouped['negative'] + 0.5))\n",
        "            \n",
        "            # Fit imputer for logit-odds\n",
        "            imputer = SimpleImputer(strategy='median')\n",
        "            imputer.fit(feature_grouped['logit_odds'].values.reshape(-1, 1))\n",
        "            self.imputers[feature] = imputer\n",
        "\n",
        "    def apply_categorical_encodings(self, X):\n",
        "        for feature in self.categorical_features:\n",
        "            # Apply OneHotEncoder\n",
        "            onehot_encoded = self.encoders[feature].transform(X[feature].values.reshape(-1, 1))\n",
        "            onehot_columns = [f\"{feature}_onehot_{i}\" for i in range(onehot_encoded.shape[1])]\n",
        "            X[onehot_columns] = onehot_encoded\n",
        "            \n",
        "            # Apply logit-odds encoding\n",
        "            logit_odds = self.imputers[feature].transform(X[feature].map(self.logit_odds_map[feature]).values.reshape(-1, 1))\n",
        "            X[f\"{feature}_logit_odds\"] = logit_odds\n",
        "            \n",
        "            # Calculate prevalence\n",
        "            X[f\"{feature}_prevalence\"] = X[feature].map(self.value_counts[feature])\n",
        "        \n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_data(data, categorical_features):\n",
        "    \n",
        "    # 1. Perform time-series stratified split\n",
        "    X_train, X_test, y_train, y_test = split_data(data)\n",
        "    # X_train, X_test, y_train, y_test = split_data_time_series(data, 'IsCanceled', n_splits=5)\n",
        "    \n",
        "    # 2. Feature Engineering\n",
        "    feature_engineer = FeatureEngineering(categorical_features)\n",
        "    feature_engineer.fit(X_train, y_train)\n",
        "    X_train_transformed = feature_engineer.transform(X_train)\n",
        "    X_test_transformed = feature_engineer.transform(X_test)\n",
        "    \n",
        "    return X_train_transformed, X_test_transformed, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'Column not found: IsCanceled'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHotel\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      2\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMeal\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      3\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarketSegment\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAgent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompany\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_cleaned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[12], line 9\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(data, categorical_features)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# X_train, X_test, y_train, y_test = split_data_time_series(data, 'IsCanceled', n_splits=5)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 2. Feature Engineering\u001b[39;00m\n\u001b[1;32m      8\u001b[0m feature_engineer \u001b[38;5;241m=\u001b[39m FeatureEngineering(categorical_features)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mfeature_engineer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m X_train_transformed \u001b[38;5;241m=\u001b[39m feature_engineer\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[1;32m     11\u001b[0m X_test_transformed \u001b[38;5;241m=\u001b[39m feature_engineer\u001b[38;5;241m.\u001b[39mtransform(X_test)\n",
            "Cell \u001b[0;32mIn[11], line 16\u001b[0m, in \u001b[0;36mFeatureEngineering.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_categorical_encodings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "Cell \u001b[0;32mIn[11], line 80\u001b[0m, in \u001b[0;36mFeatureEngineering.fit_categorical_encodings\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoders[feature] \u001b[38;5;241m=\u001b[39m onehot\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Calculate logit-odds\u001b[39;00m\n\u001b[1;32m     78\u001b[0m feature_grouped \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mgroupby(feature)\u001b[38;5;241m.\u001b[39msize(),\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     81\u001b[0m })\n\u001b[1;32m     82\u001b[0m feature_grouped[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m feature_grouped[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m feature_grouped[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     83\u001b[0m feature_grouped[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogit_odds\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog((feature_grouped[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;241m/\u001b[39m (feature_grouped[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m))\n",
            "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofPisa/AIDE/Data Mining and Machine Learning-MacBook Pro di Daniel/project/hotel-bookings-guardian/myenv/lib/python3.12/site-packages/pandas/core/groupby/generic.py:1951\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1950\u001b[0m     )\n\u001b[0;32m-> 1951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UniversityofPisa/AIDE/Data Mining and Machine Learning-MacBook Pro di Daniel/project/hotel-bookings-guardian/myenv/lib/python3.12/site-packages/pandas/core/base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Column not found: IsCanceled'"
          ]
        }
      ],
      "source": [
        "categorical_features = ['Hotel', \n",
        "                        'Meal', \n",
        "                        'MarketSegment', \n",
        "                        'DistributionChannel', \n",
        "                        'DepositType', \n",
        "                        'CustomerType', \n",
        "                        'ReservationStatus',\n",
        "                        'ReservationStatusDate',\n",
        "                        'Agent',\n",
        "                        'Company']\n",
        "\n",
        "X_train, X_test, y_train, y_test = preprocess_data(data_cleaned, categorical_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def create_model_pipeline(classifier):\n",
        "    return Pipeline([\n",
        "        ('feature_engineering', FeatureEngineering(categorical_features)),\n",
        "        ('classifier', classifier)\n",
        "    ])\n",
        "\n",
        "def evaluate_model(X, y, model_pipeline, cv=5):\n",
        "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
        "    \n",
        "    scoring = {\n",
        "        'accuracy': make_scorer(accuracy_score),\n",
        "        'precision': make_scorer(precision_score),\n",
        "        'recall': make_scorer(recall_score),\n",
        "        'f1': make_scorer(f1_score)\n",
        "    }\n",
        "    \n",
        "    results = cross_validate(model_pipeline, X, y, cv=skf, scoring=scoring)\n",
        "    \n",
        "    return {metric: np.mean(scores) for metric, scores in results.items() if metric.startswith('test_')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model_pipeline = create_model_pipeline(RandomForestClassifier())\n",
        "results = evaluate_model(data_cleaned.drop('IsCanceled', axis=1), data_cleaned['IsCanceled'], model_pipeline)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model_pipeline = create_model_pipeline(LogisticRegression())\n",
        "results = evaluate_model(data_cleaned.drop('IsCanceled', axis=1), data_cleaned['IsCanceled'], model_pipeline)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model_pipeline = create_model_pipeline(DecisionTreeClassifier())\n",
        "results = evaluate_model(data_cleaned.drop('IsCanceled', axis=1), data_cleaned['IsCanceled'], model_pipeline)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model_pipeline = create_model_pipeline(XGBClassifier())\n",
        "results = evaluate_model(data_cleaned.drop('IsCanceled', axis=1), data_cleaned['IsCanceled'], model_pipeline)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "model_pipeline = create_model_pipeline(GradientBoostingClassifier())\n",
        "results = evaluate_model(data_cleaned.drop('IsCanceled', axis=1), data_cleaned['IsCanceled'], model_pipeline)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "model_pipeline = create_model_pipeline(AdaBoostClassifier())\n",
        "results = evaluate_model(data_cleaned.drop('IsCanceled', axis=1), data_cleaned['IsCanceled'], model_pipeline)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "model_pipeline = create_model_pipeline(BaggingClassifier())\n",
        "results = evaluate_model(data_cleaned.drop('IsCanceled', axis=1), data_cleaned['IsCanceled'], model_pipeline)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import BayesianClassifier\n",
        "\n",
        "model_pipeline = create_model_pipeline(BayesianClassifier())\n",
        "results = evaluate_model(data_cleaned.drop('IsCanceled', axis=1), data_cleaned['IsCanceled'], model_pipeline)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
