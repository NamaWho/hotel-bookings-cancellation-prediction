{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119390 entries, 0 to 119389\n",
      "Data columns (total 32 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   IsCanceled                   119390 non-null  int64  \n",
      " 1   LeadTime                     119390 non-null  int64  \n",
      " 2   ArrivalDateYear              119390 non-null  int64  \n",
      " 3   ArrivalDateMonth             119390 non-null  object \n",
      " 4   ArrivalDateWeekNumber        119390 non-null  int64  \n",
      " 5   ArrivalDateDayOfMonth        119390 non-null  int64  \n",
      " 6   StaysInWeekendNights         119390 non-null  int64  \n",
      " 7   StaysInWeekNights            119390 non-null  int64  \n",
      " 8   Adults                       119390 non-null  int64  \n",
      " 9   Children                     119386 non-null  float64\n",
      " 10  Babies                       119390 non-null  int64  \n",
      " 11  Meal                         119390 non-null  object \n",
      " 12  Country                      118902 non-null  object \n",
      " 13  MarketSegment                119390 non-null  object \n",
      " 14  DistributionChannel          119390 non-null  object \n",
      " 15  IsRepeatedGuest              119390 non-null  int64  \n",
      " 16  PreviousCancellations        119390 non-null  int64  \n",
      " 17  PreviousBookingsNotCanceled  119390 non-null  int64  \n",
      " 18  ReservedRoomType             119390 non-null  object \n",
      " 19  AssignedRoomType             119390 non-null  object \n",
      " 20  BookingChanges               119390 non-null  int64  \n",
      " 21  DepositType                  119390 non-null  object \n",
      " 22  Agent                        119390 non-null  object \n",
      " 23  Company                      119390 non-null  object \n",
      " 24  DaysInWaitingList            119390 non-null  int64  \n",
      " 25  CustomerType                 119390 non-null  object \n",
      " 26  ADR                          119390 non-null  float64\n",
      " 27  RequiredCarParkingSpaces     119390 non-null  int64  \n",
      " 28  TotalOfSpecialRequests       119390 non-null  int64  \n",
      " 29  ReservationStatus            119390 non-null  object \n",
      " 30  ReservationStatusDate        119390 non-null  object \n",
      " 31  Hotel                        119390 non-null  object \n",
      "dtypes: float64(2), int64(16), object(14)\n",
      "memory usage: 29.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "import pandas as pd\n",
    "\n",
    "# Load both H1 (Resort Hotel) and H2 (City Hotel)\n",
    "data_h1 = pd.read_csv('dataset/H1.csv')\n",
    "data_h1['Hotel'] = 'H1'\n",
    "data_h2 = pd.read_csv('dataset/H2.csv')\n",
    "data_h2['Hotel'] = 'H2'\n",
    "\n",
    "# Concatenate datasets (Resort and City hotel)\n",
    "data_combined = pd.concat([data_h1, data_h2], ignore_index=True)\n",
    "\n",
    "# Initial data inspection\n",
    "data_combined.head()\n",
    "\n",
    "data_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReservationStatus\n",
       "Check-Out    75165\n",
       "Canceled     43013\n",
       "No-Show       1207\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_cleaned = data_combined.drop_duplicates()\n",
    "data_cleaned = data_combined.copy()\n",
    "\n",
    "# Convert categorical month to numerical 1-12\n",
    "months = ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "          'July', 'August', 'September', 'October', 'November', 'December']\n",
    "data_cleaned['ArrivalDateMonth'] = data_cleaned['ArrivalDateMonth'].apply(lambda x: months.index(x) + 1)\n",
    "\n",
    "# 'Children' missing values can be filled with 0\n",
    "data_cleaned['Children'] = data_cleaned['Children'].fillna(0)\n",
    "\n",
    "# Replace SC with Undefined in Meal column\n",
    "data_cleaned['Meal'] = data_cleaned['Meal'].str.strip()\n",
    "data_cleaned['Meal'] = data_cleaned['Meal'].replace('SC', 'Undefined')\n",
    "\n",
    "# deletion on rows that have missing distribution_channel, market_segment feature values.\n",
    "data_cleaned = data_cleaned.dropna(subset=['DistributionChannel', 'MarketSegment'])\n",
    "data_cleaned = data_cleaned[data_cleaned['DistributionChannel'] != 'Undefined']\n",
    "\n",
    "data_cleaned = data_cleaned.drop(columns=['Country'])\n",
    "\n",
    "# Inspect the cleaned data\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.sort_values(by=['ArrivalDateYear', 'ArrivalDateMonth', 'ArrivalDateDayOfMonth'], inplace=True)\n",
    "X = data_cleaned.drop(columns='IsCanceled')\n",
    "y = data_cleaned['IsCanceled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.adr_grouped = None\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):        \n",
    "        # Calculate the 75th percentile of ADR for each group\n",
    "        self.adr_grouped = X.groupby(['DistributionChannel', 'ReservedRoomType', 'ArrivalDateYear', 'ArrivalDateMonth'])['ADR'].quantile(0.75)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.drop(columns=['ArrivalDateWeekNumber',   \n",
    "                            'AssignedRoomType',\n",
    "                            'RequiredCarParkingSpaces'])\n",
    "\n",
    "        # Create 'LiveTime' feature\n",
    "        X['LiveTime'] = X.apply(lambda row: self.calculate_livetime(row), axis=1)\n",
    "\n",
    "        # Clean data to remove any leading/trailing spaces\n",
    "        X['ReservedRoomType'] = X['ReservedRoomType'].str.strip()\n",
    "        X['DistributionChannel'] = X['DistributionChannel'].str.strip()\n",
    "        \n",
    "        # Calculate ADRThirdQuartileDeviation\n",
    "        X['ADRThirdQuartileDeviation'] = X.apply(\n",
    "            lambda row: row['ADR'] / self.adr_grouped.get(\n",
    "                (row['DistributionChannel'], row['ReservedRoomType'], row['ArrivalDateYear'], row['ArrivalDateMonth']), 1),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        X = X.drop(columns=['LeadTime', \n",
    "                            'ADR', \n",
    "                            'ArrivalDateYear',\n",
    "                            'ArrivalDateMonth', \n",
    "                            'ArrivalDateDayOfMonth', \n",
    "                            'ReservationStatus', \n",
    "                            'ReservationStatusDate',\n",
    "                            'ReservedRoomType'])\n",
    "        \n",
    "        return X\n",
    "\n",
    "    def calculate_livetime(self, row):\n",
    "        current_date = datetime.now()\n",
    "        arrival_date = datetime(row['ArrivalDateYear'], row['ArrivalDateMonth'], row['ArrivalDateDayOfMonth'])\n",
    "        booking_date = arrival_date - timedelta(days=row['LeadTime'])\n",
    "        \n",
    "        if row['ReservationStatus'] == 'Check-Out':  # \"A\" type (effective bookings)\n",
    "            return row['LeadTime']\n",
    "        elif row['ReservationStatus'] == 'Canceled' or row['ReservationStatus'] == 'No-Show':  # \"B\" type (canceled bookings)\n",
    "            reservation_status_date = datetime.strptime(row['ReservationStatusDate'], \"%Y-%m-%d\")\n",
    "            return (reservation_status_date - booking_date).days\n",
    "        else:  # \"C\" type (future bookings)\n",
    "            return (current_date - booking_date).days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogitOddsEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target_col='IsCanceled', min_frequency=0.02, smoothing=1e-6):\n",
    "        self.target_col = target_col\n",
    "        self.min_frequency = min_frequency\n",
    "        self.smoothing = smoothing\n",
    "        self.logit_odds_map = {}\n",
    "        self.global_mean_logit_odds = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Store global logit odds as a fallback for unseen categories\n",
    "        global_mean = y.mean()\n",
    "        self.global_mean_logit_odds = np.log(global_mean / (1 - global_mean))\n",
    "\n",
    "        for col in X.columns:\n",
    "            counts = X[col].value_counts(normalize=True)\n",
    "            common_levels = counts[counts >= self.min_frequency].index\n",
    "            group_data = X[[col]].copy()\n",
    "            group_data[self.target_col] = y\n",
    "            \n",
    "            # Calculate logit odds with proper handling of 0 and 1 values\n",
    "            logit_odds = group_data.groupby(col)[self.target_col].mean().apply(\n",
    "                lambda x: np.log(np.clip(x, self.smoothing, 1 - self.smoothing) / \n",
    "                                 (1 - np.clip(x, self.smoothing, 1 - self.smoothing)))\n",
    "            )\n",
    "            self.logit_odds_map[col] = logit_odds.reindex(common_levels).fillna(self.global_mean_logit_odds)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_encoded = X.copy()\n",
    "        for col in X.columns:\n",
    "            # Map the logit odds to the column, filling with the global mean logit odds if not found\n",
    "            X_encoded[col] = X[col].map(self.logit_odds_map[col]).fillna(self.global_mean_logit_odds)\n",
    "        return X_encoded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Define preprocessing for numerical and categorical columns\n",
    "numerical_features = ['LiveTime', \n",
    "                      'StaysInWeekendNights', \n",
    "                      'StaysInWeekNights', \n",
    "                      'Adults', \n",
    "                      'Children', \n",
    "                      'Babies', \n",
    "                      'ADRThirdQuartileDeviation', \n",
    "                      'IsRepeatedGuest', \n",
    "                      'PreviousCancellations', \n",
    "                      'PreviousBookingsNotCanceled', \n",
    "                      'BookingChanges', \n",
    "                      'DaysInWaitingList', \n",
    "                      'TotalOfSpecialRequests']\n",
    "categorical_features = ['DepositType', \n",
    "                        'DistributionChannel', \n",
    "                        'CustomerType', \n",
    "                        'Meal', \n",
    "                        'MarketSegment', \n",
    "                        'Hotel',\n",
    "                        'Agent', \n",
    "                        'Company']\n",
    "\n",
    "# Preprocessing pipeline for numerical and categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features[:-2]),  # Apply OHE to other categorical features\n",
    "        ('logit_odds', LogitOddsEncoder(), ['Agent', 'Company']) \n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielnamaki/Library/CloudStorage/OneDrive-UniversityofPisa/AIDE/Data Mining and Machine Learning-MacBook Pro di Daniel/project/hotel-bookings-guardian/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/danielnamaki/Library/CloudStorage/OneDrive-UniversityofPisa/AIDE/Data Mining and Machine Learning-MacBook Pro di Daniel/project/hotel-bookings-guardian/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/danielnamaki/Library/CloudStorage/OneDrive-UniversityofPisa/AIDE/Data Mining and Machine Learning-MacBook Pro di Daniel/project/hotel-bookings-guardian/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/danielnamaki/Library/CloudStorage/OneDrive-UniversityofPisa/AIDE/Data Mining and Machine Learning-MacBook Pro di Daniel/project/hotel-bookings-guardian/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Users/danielnamaki/Library/CloudStorage/OneDrive-UniversityofPisa/AIDE/Data Mining and Machine Learning-MacBook Pro di Daniel/project/hotel-bookings-guardian/myenv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.799176</td>\n",
       "      <td>0.835994</td>\n",
       "      <td>0.570319</td>\n",
       "      <td>0.676322</td>\n",
       "      <td>0.832236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.792391</td>\n",
       "      <td>0.799127</td>\n",
       "      <td>0.597567</td>\n",
       "      <td>0.679770</td>\n",
       "      <td>0.828843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.801578</td>\n",
       "      <td>0.813556</td>\n",
       "      <td>0.611209</td>\n",
       "      <td>0.693573</td>\n",
       "      <td>0.838618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.734844</td>\n",
       "      <td>0.651870</td>\n",
       "      <td>0.604913</td>\n",
       "      <td>0.626979</td>\n",
       "      <td>0.708300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.747037</td>\n",
       "      <td>0.677710</td>\n",
       "      <td>0.599467</td>\n",
       "      <td>0.634686</td>\n",
       "      <td>0.769474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.787013</td>\n",
       "      <td>0.793915</td>\n",
       "      <td>0.573484</td>\n",
       "      <td>0.664643</td>\n",
       "      <td>0.807102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bayesian</td>\n",
       "      <td>0.642871</td>\n",
       "      <td>0.520780</td>\n",
       "      <td>0.683091</td>\n",
       "      <td>0.585712</td>\n",
       "      <td>0.743116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.810283</td>\n",
       "      <td>0.844743</td>\n",
       "      <td>0.597217</td>\n",
       "      <td>0.697826</td>\n",
       "      <td>0.852476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1 Score   ROC AUC\n",
       "0        Random Forest  0.799176   0.835994  0.570319  0.676322  0.832236\n",
       "1  Logistic Regression  0.792391   0.799127  0.597567  0.679770  0.828843\n",
       "2             AdaBoost  0.801578   0.813556  0.611209  0.693573  0.838618\n",
       "3        Decision Tree  0.734844   0.651870  0.604913  0.626979  0.708300\n",
       "4  K-Nearest Neighbors  0.747037   0.677710  0.599467  0.634686  0.769474\n",
       "5              Bagging  0.787013   0.793915  0.573484  0.664643  0.807102\n",
       "6             Bayesian  0.642871   0.520780  0.683091  0.585712  0.743116\n",
       "7              XGBoost  0.810283   0.844743  0.597217  0.697826  0.852476"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_validate\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Definisci tutti i modelli da valutare\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Bagging': BaggingClassifier(random_state=42),\n",
    "    'Bayesian': GaussianNB(),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "def confusion_matrix_scorer(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return cm\n",
    "\n",
    "# Define scoring metrics for cross_validate\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc',\n",
    "    # 'confusion_matrix': make_scorer(confusion_matrix_scorer)  # Add confusion matrix to scoring\n",
    "}\n",
    "\n",
    "# TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Lista per salvare i risultati\n",
    "all_results = []\n",
    "\n",
    "# Esegui TimeSeriesSplit per ognuno dei modelli\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    # Create a pipeline with SMOTE and the model\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('feature_engineering', FeatureEngineering()),  # Feature engineering\n",
    "        ('preprocessing', preprocessor),  # Preprocessing (StandardScaler, OneHotEncoder, Logit-Odds)\n",
    "        ('smote', SMOTE(random_state=42)),  # Apply SMOTE to balance the classes\n",
    "        ('model', model)  # The current model\n",
    "    ])\n",
    "    \n",
    "    # Perform cross-validation with the pipeline and TimeSeriesSplit\n",
    "    cv_results = cross_validate(pipeline, X, y, cv=tscv, scoring=scoring, return_train_score=False)\n",
    "    \n",
    "    # Store the results\n",
    "    all_results.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': np.mean(cv_results['test_accuracy']),\n",
    "        'Precision': np.mean(cv_results['test_precision']),\n",
    "        'Recall': np.mean(cv_results['test_recall']),\n",
    "        'F1 Score': np.mean(cv_results['test_f1']),\n",
    "        'ROC AUC': np.mean(cv_results['test_roc_auc']),\n",
    "        # 'Confusion Matrices': cv_results['test_confusion_matrix']  # This will store the confusion matrices for each fold\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
