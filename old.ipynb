{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset available [here](https://www.sciencedirect.com/science/article/pii/S2352340918315191?via%3Dihub)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "Pp6o37MGITM1",
        "outputId": "859d0c44-0c78-496f-d6fe-b96068c72337"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IsCanceled</th>\n",
              "      <th>LeadTime</th>\n",
              "      <th>ArrivalDateYear</th>\n",
              "      <th>ArrivalDateMonth</th>\n",
              "      <th>ArrivalDateWeekNumber</th>\n",
              "      <th>ArrivalDateDayOfMonth</th>\n",
              "      <th>StaysInWeekendNights</th>\n",
              "      <th>StaysInWeekNights</th>\n",
              "      <th>Adults</th>\n",
              "      <th>Children</th>\n",
              "      <th>...</th>\n",
              "      <th>DepositType</th>\n",
              "      <th>Agent</th>\n",
              "      <th>Company</th>\n",
              "      <th>DaysInWaitingList</th>\n",
              "      <th>CustomerType</th>\n",
              "      <th>ADR</th>\n",
              "      <th>RequiredCarParkingSpaces</th>\n",
              "      <th>TotalOfSpecialRequests</th>\n",
              "      <th>ReservationStatus</th>\n",
              "      <th>ReservationStatusDate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>342</td>\n",
              "      <td>2015</td>\n",
              "      <td>July</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>No Deposit</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>0</td>\n",
              "      <td>Transient</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Check-Out</td>\n",
              "      <td>2015-07-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>737</td>\n",
              "      <td>2015</td>\n",
              "      <td>July</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>No Deposit</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>0</td>\n",
              "      <td>Transient</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Check-Out</td>\n",
              "      <td>2015-07-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2015</td>\n",
              "      <td>July</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>No Deposit</td>\n",
              "      <td>NULL</td>\n",
              "      <td>NULL</td>\n",
              "      <td>0</td>\n",
              "      <td>Transient</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Check-Out</td>\n",
              "      <td>2015-07-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>2015</td>\n",
              "      <td>July</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>No Deposit</td>\n",
              "      <td>304</td>\n",
              "      <td>NULL</td>\n",
              "      <td>0</td>\n",
              "      <td>Transient</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Check-Out</td>\n",
              "      <td>2015-07-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>2015</td>\n",
              "      <td>July</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>No Deposit</td>\n",
              "      <td>240</td>\n",
              "      <td>NULL</td>\n",
              "      <td>0</td>\n",
              "      <td>Transient</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Check-Out</td>\n",
              "      <td>2015-07-03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   IsCanceled  LeadTime  ArrivalDateYear ArrivalDateMonth  \\\n",
              "0           0       342             2015             July   \n",
              "1           0       737             2015             July   \n",
              "2           0         7             2015             July   \n",
              "3           0        13             2015             July   \n",
              "4           0        14             2015             July   \n",
              "\n",
              "   ArrivalDateWeekNumber  ArrivalDateDayOfMonth  StaysInWeekendNights  \\\n",
              "0                     27                      1                     0   \n",
              "1                     27                      1                     0   \n",
              "2                     27                      1                     0   \n",
              "3                     27                      1                     0   \n",
              "4                     27                      1                     0   \n",
              "\n",
              "   StaysInWeekNights  Adults  Children  ...      DepositType        Agent  \\\n",
              "0                  0       2         0  ...  No Deposit              NULL   \n",
              "1                  0       2         0  ...  No Deposit              NULL   \n",
              "2                  1       1         0  ...  No Deposit              NULL   \n",
              "3                  1       1         0  ...  No Deposit               304   \n",
              "4                  2       2         0  ...  No Deposit               240   \n",
              "\n",
              "       Company DaysInWaitingList CustomerType   ADR  RequiredCarParkingSpaces  \\\n",
              "0         NULL                 0    Transient   0.0                         0   \n",
              "1         NULL                 0    Transient   0.0                         0   \n",
              "2         NULL                 0    Transient  75.0                         0   \n",
              "3         NULL                 0    Transient  75.0                         0   \n",
              "4         NULL                 0    Transient  98.0                         0   \n",
              "\n",
              "   TotalOfSpecialRequests ReservationStatus ReservationStatusDate  \n",
              "0                       0         Check-Out            2015-07-01  \n",
              "1                       0         Check-Out            2015-07-01  \n",
              "2                       0         Check-Out            2015-07-02  \n",
              "3                       0         Check-Out            2015-07-02  \n",
              "4                       1         Check-Out            2015-07-03  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "# load data\n",
        "data_h1 = pd.read_csv('./dataset/H1.csv')\n",
        "# data_h2 = pd.read_csv('./dataset/H2.csv')\n",
        "# data = pd.concat([data_h1, data_h2], ignore_index=True)\n",
        "data = data_h1\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(33968, 31)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove duplicates\n",
        "data_cleaned = data.drop_duplicates()\n",
        "\n",
        "# Convert ArrivalDateMonth to numerical\n",
        "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
        "data_cleaned.loc[:, 'ArrivalDateMonth'] = data_cleaned['ArrivalDateMonth'].apply(lambda x: months.index(x) + 1)\n",
        "\n",
        "data_cleaned.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instead of making a stratified split by the outcome (IsCanceled) based on the dimension of the booking creation date, an approach usually employed in time series is applied, convenience splitting. Order the dataset by arrival date of bookings and create blocks of \"month/year\". Merge a 75% stratified split of each block into a training dataset and the remaining 25% into a test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "\n",
        "def split_data(data):\n",
        "    \"\"\"\n",
        "    Perform stratified split on the data\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "        The data to split\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X_train : pd.DataFrame\n",
        "        The training data\n",
        "    X_test : pd.DataFrame   \n",
        "        The testing data\n",
        "    y_train : pd.Series\n",
        "        The training target\n",
        "    y_test : pd.Series\n",
        "        The testing target\n",
        "    \"\"\"\n",
        "    \n",
        "    data = data.sort_values(by=['ArrivalDateYear', 'ArrivalDateMonth', 'ArrivalDateDayOfMonth'])\n",
        "    \n",
        "    # y = data['IsCanceled']\n",
        "    # X = data.drop(columns=['IsCanceled'])\n",
        "    \n",
        "    # X['YearMonth'] = X['ArrivalDateYear'].astype(str) + '-' + X['ArrivalDateMonth'].astype(str)\n",
        "    \n",
        "    data['YearMonth'] = data['ArrivalDateYear'].astype(str) + '-' + data['ArrivalDateMonth'].astype(str)\n",
        "\n",
        "    # X_train_list, X_test_list, y_train_list, y_test_list = [], [], [], []\n",
        "    \n",
        "    # # Loop over each block and perform stratified split\n",
        "    # for block in X['YearMonth'].unique():\n",
        "    #     X_block = X[X['YearMonth'] == block].drop(columns=['YearMonth'])\n",
        "    #     y_block = y[X['YearMonth'] == block]\n",
        "        \n",
        "    #     X_train_block, X_test_block, y_train_block, y_test_block = train_test_split(\n",
        "    #         X_block, y_block, test_size=0.25, stratify=y_block, random_state=42)\n",
        "        \n",
        "    #     X_train_list.append(X_train_block)\n",
        "    #     X_test_list.append(X_test_block)\n",
        "    #     y_train_list.append(y_train_block)\n",
        "    #     y_test_list.append(y_test_block)\n",
        "    \n",
        "    # X_train = pd.concat(X_train_list)\n",
        "    # X_test = pd.concat(X_test_list)\n",
        "    # y_train = pd.concat(y_train_list)\n",
        "    # y_test = pd.concat(y_test_list)\n",
        "\n",
        "    train_list, test_list = [], []\n",
        "    \n",
        "    # Loop over each block and perform stratified split\n",
        "    for block in data['YearMonth'].unique():\n",
        "        block_data = data[data['YearMonth'] == block]\n",
        "        \n",
        "        train_block, test_block = train_test_split(\n",
        "            block_data, test_size=0.25, stratify=block_data['IsCanceled'], random_state=42)\n",
        "        \n",
        "        train_list.append(train_block)\n",
        "        test_list.append(test_block)\n",
        "\n",
        "    train_data = pd.concat(train_list)\n",
        "    test_data = pd.concat(test_list)\n",
        "\n",
        "    # return X_train, X_test, y_train, y_test\n",
        "    return train_data, test_data\n",
        "\n",
        "def split_data_time_series(data, target_column, n_splits=5):\n",
        "    \"\"\"\n",
        "    Perform time series split on the data\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "        The data to split\n",
        "    target_column : str\n",
        "        The target column\n",
        "    n_splits : int\n",
        "        The number of splits to perform\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X_train : pd.DataFrame\n",
        "        The training data\n",
        "    X_test : pd.DataFrame\n",
        "        The testing data\n",
        "    y_train : pd.Series\n",
        "        The training target\n",
        "    y_test : pd.Series  \n",
        "        The testing target\n",
        "    \"\"\"\n",
        "    data = data.sort_values(by=['ArrivalDateYear', 'ArrivalDateMonth', 'ArrivalDateDayOfMonth'])\n",
        "    \n",
        "    X = data.drop(target_column, axis=1)\n",
        "    y = data[target_column]\n",
        "    \n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "    \n",
        "    for train_index, test_index in tscv.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "        \n",
        "        # Ensure stratification by checking the distribution of the target variable\n",
        "        if np.all(np.bincount(y_train) > 0) and np.all(np.bincount(y_test) > 0):\n",
        "            break\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Selection and Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.base import BaseEstimator, TransformerMixin\n",
        "# import datetime\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "# from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Custom transformer for feature engineering\n",
        "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        # self.categorical_features = categorical_features\n",
        "        # self.cardinality_threshold = cardinality_threshold\n",
        "        # self.encoders = {}\n",
        "        # self.imputers = {}\n",
        "\n",
        "        # self.value_counts = {}\n",
        "        # self.logit_odds_map = {}\n",
        "        self.cat_imputer = SimpleImputer(strategy='most_frequent')  # For categorical columns\n",
        "        self.num_imputer = SimpleImputer(strategy='mean')  # For numerical columns\n",
        "        self.encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)  # One-hot encoder\n",
        "        self.scaler = StandardScaler()  \n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        # Fit any transformers (e.g., imputer learns most frequent values, scaler learns the mean and std)\n",
        "        X_cat = X[['Meal', 'Country', 'MarketSegment', 'DistributionChannel', 'CustomerType', 'ReservationStatus']]\n",
        "        X_num = X[['LeadTime', 'StaysInWeekendNights', 'StaysInWeekNights', 'Adults', 'Children', 'ADR']]\n",
        "        \n",
        "        # self.fit_categorical_encodings(X)\n",
        "\n",
        "        # Fit the transformers\n",
        "        self.cat_imputer.fit(X_cat)\n",
        "        self.num_imputer.fit(X_num)\n",
        "        self.encoder.fit(self.cat_imputer.transform(X_cat))\n",
        "        self.scaler.fit(self.num_imputer.transform(X_num))\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        # X = X.copy()\n",
        "\n",
        "        # # Replace LeadTime with LiveTime\n",
        "        # X['LiveTime'] = X.apply(self.calculate_livetime, axis=1)\n",
        "        \n",
        "        # # Replace ADR with ADRThirdQuartileDeviation\n",
        "        # X = self.calculate_adr_third_quartile_deviation(X)\n",
        "        \n",
        "        # # Apply categorical encodings\n",
        "        # X = self.apply_categorical_encodings(X)\n",
        "        \n",
        "        # # Drop the original columns\n",
        "        # columns_to_drop = ['LeadTime', 'ADR', 'ArrivalDateMonth', 'ArrivalDateDayOfMonth', \n",
        "        #                    'ArrivalDateWeekNumber', 'ArrivalDateYear', 'Country', \"AssignedRoomType\",\n",
        "        #                    'RequiredCarParkingSpaces', 'ReservedRoomType']\n",
        "        # columns_to_drop.extend(self.categorical_features)\n",
        "        # X.drop(columns=columns_to_drop, inplace=True)\n",
        "         \n",
        "        # Apply transformations to the data\n",
        "        X_cat = X[['Meal', 'Country', 'MarketSegment', 'DistributionChannel', 'CustomerType', 'ReservationStatus']]\n",
        "        X_num = X[['LeadTime', 'StaysInWeekendNights', 'StaysInWeekNights', 'Adults', 'Children', 'ADR']]\n",
        "\n",
        "       # Apply transformations\n",
        "        X_cat_imputed = self.cat_imputer.transform(X_cat)\n",
        "        X_num_imputed = self.num_imputer.transform(X_num)\n",
        "        X_cat_encoded = self.encoder.transform(X_cat_imputed)\n",
        "        X_num_scaled = self.scaler.transform(X_num_imputed)\n",
        "        \n",
        "        # Return combined transformed data\n",
        "        return np.hstack((X_cat_encoded, X_num_scaled))\n",
        "\n",
        "        \n",
        "        return X\n",
        "    \n",
        "    def calculate_livetime(self, row):\n",
        "        arrival_date = datetime.date(row['ArrivalDateYear'], row['ArrivalDateMonth'], row['ArrivalDateDayOfMonth'])\n",
        "        booking_date = arrival_date - datetime.timedelta(days=row['LeadTime'])\n",
        "        reservation_status_date = datetime.datetime.strptime(row['ReservationStatusDate'], '%Y-%m-%d').date()\n",
        "\n",
        "        if row['ReservationStatus'] == 'Check-Out' or row['ReservationStatus'] == 'No-Show':\n",
        "            return row['LeadTime']\n",
        "        else:\n",
        "            # If the reservation is canceled, the live time is the difference between the booking date and the cancel date\n",
        "            return (reservation_status_date - booking_date).days\n",
        "    \n",
        "    def calculate_adr_third_quartile_deviation(self, X):\n",
        "        # Group by the required factors\n",
        "        grouped = X.groupby(['DistributionChannel', 'ReservedRoomType', 'ArrivalDateWeekNumber', 'ArrivalDateYear'])\n",
        "\n",
        "        # Calculate the third quartile for each group\n",
        "        adr_third_quartile = grouped['ADR'].transform(lambda x: x.quantile(0.75))\n",
        "\n",
        "        # Calculate the deviation\n",
        "        X['ADRThirdQuartileDeviation'] = X['ADR'] / adr_third_quartile\n",
        "\n",
        "        # Handle cases where third quartile is 0 (unlikely, but possible)\n",
        "        X['ADRThirdQuartileDeviation'] = X['ADRThirdQuartileDeviation'].fillna(0)\n",
        "\n",
        "        return X\n",
        "    \n",
        "    def fit_categorical_encodings(self, X):\n",
        "        for feature in self.categorical_features:\n",
        "            # Calculate value counts and keep only those above the threshold\n",
        "            value_counts = X[feature].value_counts(normalize=True)\n",
        "            frequent_categories = value_counts[value_counts >= self.cardinality_threshold].index.tolist()\n",
        "            \n",
        "            # Fit OneHotEncoder for frequent categories\n",
        "            onehot = OneHotEncoder(handle_unknown='ignore')\n",
        "            onehot.fit(X[feature].values.reshape(-1, 1))\n",
        "            self.encoders[feature] = onehot\n",
        "            \n",
        "            # Calculate logit-odds\n",
        "            feature_grouped = pd.DataFrame({\n",
        "                'total': X.groupby(feature).size(),\n",
        "                'positive': X.groupby(feature)['IsCanceled'].sum()\n",
        "            })\n",
        "            feature_grouped['negative'] = feature_grouped['total'] - feature_grouped['positive']\n",
        "            feature_grouped['logit_odds'] = np.log((feature_grouped['positive'] + 0.5) / (feature_grouped['negative'] + 0.5))\n",
        "            \n",
        "            # Fit imputer for logit-odds\n",
        "            imputer = SimpleImputer(strategy='median')\n",
        "            imputer.fit(feature_grouped['logit_odds'].values.reshape(-1, 1))\n",
        "            self.imputers[feature] = imputer\n",
        "\n",
        "            # Store value counts and logit-odds map for later use\n",
        "            self.value_counts[feature] = value_counts\n",
        "            self.logit_odds_map[feature] = feature_grouped['logit_odds'].to_dict()\n",
        "\n",
        "    def apply_categorical_encodings(self, X):\n",
        "        for feature in self.categorical_features:\n",
        "            # Apply OneHotEncoder\n",
        "            onehot_encoded = self.encoders[feature].transform(X[feature].values.reshape(-1, 1)).toarray()\n",
        "            onehot_columns = [f\"{feature}_onehot_{i}\" for i in range(onehot_encoded.shape[1])]\n",
        "\n",
        "            # Ensure the number of columns match\n",
        "            if onehot_encoded.shape[1] == len(onehot_columns):\n",
        "                onehot_df = pd.DataFrame(onehot_encoded, columns=onehot_columns, index=X.index)\n",
        "                X = pd.concat([X, onehot_df], axis=1)\n",
        "            else:\n",
        "                raise ValueError(f\"Mismatch in number of one-hot encoded columns for feature {feature}\")\n",
        "            \n",
        "            # Apply logit-odds encoding\n",
        "            # logit_odds = self.imputers[feature].transform(X[feature].map(self.logit_odds_map[feature]).values.reshape(-1, 1))\n",
        "            # X[f\"{feature}_logit_odds\"] = logit_odds\n",
        "            \n",
        "            # Calculate prevalence\n",
        "            X[f\"{feature}_prevalence\"] = X[feature].map(self.value_counts[feature])\n",
        "        \n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_data(data, categorical_features):\n",
        "    \n",
        "    # 1. Perform time-series stratified split\n",
        "    # X_train, X_test, y_train, y_test = split_data(data)\n",
        "    # X_train, X_test, y_train, y_test = split_data_time_series(data, 'IsCanceled', n_splits=5)\n",
        "    train_data, test_data = split_data(data)\n",
        "\n",
        "    # 2. Feature Engineering\n",
        "    feature_engineer = FeatureEngineering(categorical_features)\n",
        "    feature_engineer.fit(train_data)\n",
        "    train_data_transformed = feature_engineer.transform(train_data)\n",
        "    test_data_transformed = feature_engineer.transform(test_data)\n",
        "    \n",
        "    # 3. Separate features and target\n",
        "    y_train = train_data_transformed['IsCanceled']\n",
        "    X_train = train_data_transformed.drop(columns=['IsCanceled'])\n",
        "    \n",
        "    y_test = test_data_transformed['IsCanceled']\n",
        "    X_test = test_data_transformed.drop(columns=['IsCanceled'])\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_features = ['Hotel', \n",
        "                        'Meal', \n",
        "                        'MarketSegment', \n",
        "                        'DistributionChannel', \n",
        "                        'DepositType', \n",
        "                        'CustomerType', \n",
        "                        'ReservationStatus',\n",
        "                        'ReservationStatusDate',\n",
        "                        'Agent',\n",
        "                        'Company']\n",
        "\n",
        "X_train, X_test, y_train, y_test = preprocess_data(data_cleaned, categorical_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def create_model_pipeline(classifier):\n",
        "    return Pipeline([\n",
        "        ('feature_engineering', FeatureEngineering(categorical_features)),\n",
        "        ('classifier', classifier)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the cleaned data for pipeline training\n",
        "X = data_cleaned.drop(columns='IsCanceled')\n",
        "y = data_cleaned['IsCanceled']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating the full pipeline with feature engineering and model\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('feature_engineering', FeatureEngineering()),  # Feature engineering step\n",
        "    ('model', RandomForestClassifier())  # You can replace this with any model\n",
        "])\n",
        "\n",
        "# Fitting the pipeline to the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Fit the pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate with cross-validation\n",
        "scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
        "print(f'Cross-validated accuracy: {scores.mean():.4f}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
